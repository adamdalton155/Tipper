\chapter{Methodology}
\section{Development Methodology}
When it came deciding on a methodology we had to think about it from two different sides. One is the software methodology and the other is the research methodology. To start we will discuss the software methodology we used. Initially we decided to look at the most common methodologies used in industry. We started with Waterfall, a rigid/linear model that requires the completion of one feature before moving onto the next\cite{heriyanti2020design}. We felt that because of the nature of software development as we know so far and also our schedule, this just didn't fit our needs. This is the first time we have had to pick, design and implement an application and so required a lot of learning as we made progress and having such a rigid model didn't suit us. Waterfall goes in the following order, Requirements, Design, Implement, Verification and Maintenance.

The next methodology we looked into using for planning the development was Rapid Application Development (RAD). For this methodology, the developers have the ability to adjust the development process much easier than Waterfall. In industry this does result in a lower investment cost which does make it a favourable choice\cite{rad}. It seemed to fit with our needs of being able to make changes to the application without having to complete a feature before being able to change too much. In RAD, the development is split into four phases, requirements planning, user design, construction, and cut-over. From the introduction we can see already why RAD might be a suitable choice. From speaking to the workers, understanding what exactly would be required for this app to be appropriate, building the app and then cut-off is the completion of the app. 

There were somethings that did worry us about using RAD though. Even though RAD is perfect for building products that has a specific user-base, it requires it's developers to be highly skilled and proficient in their chosen technologies\cite{rad}. One of the various reasons for choosing this project was to learn some new technologies such as the React-Native framework, improving existing skills in JavaScript and learning a new database model. 

Finally we looked at Agile development methodology. Agile follows an iterative approach to its development\cite{manifesto2001agile}. The process goes something like this, Scope out and prioritize projects, Diagram requirements for the initial sprint, Construction/iteration, Release the iteration into production, Production and ongoing support for the software release, Retirement. By following this methodology, requirements discovery and solutions improve through the collaborative effort of self-organizing and cross-functional teams. There is a lot to like Agile, it promotes better communication, is flexible but on the other hand it can be difficult to predict how development may go\cite{manifesto2001agile}. Often the product that is released isn't even one-hundred percent complete, with features missing that are added in subsequent updates. This would be applicable to our application. We have ideas that we believed would be great additions but would make the scope far too big for the time being.

When we weighed up the the different aspects of each methodology, the pros and cons and what was required for the project, we knew that Waterfall simply did not fit our needs. When examining Agile and Rapid Application Development it was a tough choice to make. Both certainly fit our needs. But when we see that RAD was used for projects where the user-base is specific, it made sense for us to choose that methodology. It fit the needs of needing to make changes with as little impact on the overall progress. RAD is perfect for small to medium projects with small to medium sized teams. 

\section{Research Methodology}
Upon deciding on which software methodology we intended to use, we then had to look at what research methodology we would use, primarily for making decisions on which technologies we would like to use. There are three research methodologies we discussed and compared. The first was Quantitative research. This involves the measurement and testing using numerical data. Quantitative methodology is typically used when the research aims and objectives are confirmatory in nature. This could be how many people have become users of a technology or how many iterations of a technology. This is generally seen as an indication of quality of the product. If it has a large user-base, and has numerous updates then you can potentially see it as a good product to use\cite{snyder1989quantitative}.

The other research methodology that we looked at was Qualitative. This refers to research which focuses on collecting and analysing words (written or spoken) and textual data\cite{ezzy2013qualitative}. How this can be applied is by reading the documentation of a technology to understand what it offers and does it apply to what you want. Another form is reading forums/reviews of the technology to see what other developers are saying. This can be very beneficial as we can can get an in-depth understanding of how to use the technology, what others opinions are about trying to implement the technology. It's also a great indication of when not use a particular technology.

Finally we looked at Mixed-method methodology which simply attempts to combine both Quantitative and Qualitative methodologies\cite{creswell1999mixed}. First of all this was what we thought was this is the best methodology to use when researching the technologies to use. There are various metrics that can be observed when choosing a service to use. We took into account what the technology offered and determined if that would fit with our requirements. We did this by reading documentation, looking at other sources such as forums or videos to see what they recommended to try and solve the problem. But then on the other hand we would see how many resources there are. If we see a technology that had very few discussions online or short documentations, we agreed that could be an issue if we became unsure of how to build a feature. Developing software is a broad and difficult process with so many variables to take into account and to limit the information we could find to either metric based or discussion based seemed restricting. 

Now that we knew how we would go about developing and researching, we needed to now understand how to plan this. First we gathered the requirements based on research and interviewing and so understood exactly what was needed for this to be complete project. From here we could understand how the project will look. What would be on each screen (screens are just components that the user sees when using the app) and what the function of that screen is. Then we looked at designing the features of the app. For example the login, how does the user login, what are the requirements the user needs to login and what should be the end result of the user successfully or unsuccessfully logging in.

We also realised we needed to prototype features of the project quickly. Such as the user being able to reset their password for logging in. Through this we needed to get this working quickly as a way for us to understand how this should work, get the feature working and then adjust accordingly if the implementation satisfies the requirement. This helped us to identify the quality of the feature. 

Finally this help us understand how we should go about testing the code. We realised early on that the majority of the features are tightly coupled and one leads into another. We noted that there wasn't much input from the user. The calculation of the tip feature requires two inputs, the bill total and percentage. So the formula for the calculation has to be correct and tested. We also had to ensure that the security features (that being the verification codes and password) were correct along with the ability for the user to create the account. So, in short testing the application wasn't huge, just making sure that the different features of the application worked as intended as for a lot of the features work together. 

This style of testing is known as unit testing. Essentially checking that every individual feature works as intended\cite{runeson2006survey}. Considering there aren't that many calculations in the app, boundary analysis testing wasn't necessary. We also looked at other testing methodologies to check if they were needed. For example, this app isn't a massive project so doesn't require too much stress testing. Upon completion of the app, Acceptance Testing was performed to make sure the whole project worked as intended, from start to finish with no issues. 